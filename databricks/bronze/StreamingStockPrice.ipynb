{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e04d0ded-d0a2-4ab5-bae3-43c688e69e55",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "EVENT_HUB_CONNECTION_STR = dbutils.secrets.get(scope = \"eventhubs\", key = \"EVENT_HUB_CONNECTION_STR\")\n",
    "\n",
    "EH_NAMESPACE                    = 'predictstockpriceskafka'\n",
    "EH_NAME                         = 'liveprices'\n",
    "\n",
    "EH_CONN_STR                     = EVENT_HUB_CONNECTION_STR\n",
    "\n",
    "KAFKA_OPTIONS = {\n",
    "  \"kafka.bootstrap.servers\"  : f\"{EH_NAMESPACE}.servicebus.windows.net:9093\",\n",
    "  \"subscribe\"                : EH_NAME,\n",
    "  \"kafka.sasl.mechanism\"     : \"PLAIN\",\n",
    "  \"kafka.security.protocol\"  : \"SASL_SSL\",\n",
    "  \"kafka.sasl.jaas.config\"   : f\"kafkashaded.org.apache.kafka.common.security.plain.PlainLoginModule required username=\\\"$ConnectionString\\\" password=\\\"{EH_CONN_STR}\\\";\",\n",
    "  \"startingOffsets\"          : \"earliest\",\n",
    "  \"failOnDataLoss\"           : \"false\",\n",
    "}\n",
    "\n",
    "spark.conf.set(\n",
    "    \"fs.azure.account.key.stocksstorage.dfs.core.windows.net\",\n",
    "    dbutils.secrets.get(scope=\"blobstorage\", key=\"accesskey\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "068cc8f2-dade-4c05-9a4f-5281a71193a5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import StructType, StructField, StringType\n",
    "\n",
    "\n",
    "schema = StructType([\n",
    "    StructField(\"ticker\", StringType()),\n",
    "    StructField(\"price\", StringType()),\n",
    "    StructField(\"time\", StringType())\n",
    "])\n",
    "\n",
    "spark.readStream \\\n",
    "    .format(\"kafka\") \\\n",
    "    .options(**KAFKA_OPTIONS) \\\n",
    "    .load() \\\n",
    "    .selectExpr(\"CAST(value AS STRING) as json_str\") \\\n",
    "    .select(from_json(col(\"json_str\"), schema).alias(\"data\")) \\\n",
    "    .select(\"data.*\") \\\n",
    "    .writeStream \\\n",
    "    .format(\"delta\") \\\n",
    "    .outputMode(\"append\") \\\n",
    "    .option(\"checkpointLocation\", \"abfss://plstocks@stocksstorage.dfs.core.windows.net/checkpoints/bronze\") \\\n",
    "    .trigger(availableNow=True) \\\n",
    "    .toTable(\"plstocks.bronze_prices_raw_stream\")\n",
    "\n",
    "\n",
    "spark.sql(\"SELECT * FROM plstocks.bronze_prices_raw_stream ORDER BY time DESC\").display()\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "StreamingStockPrice",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
